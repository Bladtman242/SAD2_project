\section*{A Stream Based Approach}
Streaming algorithms provide excellent solutions to many problems where data
sets are large enough that we wish (or need) to sacrifice correctness for low
memory usage and time consumption.
From \texttt{Ikonomovska\--Zelke}:
\begin{quote}
Streaming algorithms drop the demand of random access to the input. Rather, the input
is assumed to arrive in arbitrary order as an input stream. Moreover, streaming algorithms
are designed to settle for a working memory that is much smaller than the size of the input.
\end{quote}
To be precise, they require that the size of the working memory is sublinear in both the cardinality of the stream and the universe.
Due to this nature of streaming algorithms they are not commonly used for
problems that require analysing parts of non-constant, non-parameterized size
of the data set, for each given input. Hence an approach to
solve our problem --- sorting -- based on streaming algorithms will provide some interesting
trade-offs.

We begin with a definition of our stream, and a simple algorithm for our
problem. Our input is a turnstile stream. The universe
$U$ is the set of movies in our database, and each stream item is a pair
$(j,r) \in U\times \left(\left[1,10\right]\cap \mathbb{N}\right)$.
With our definition of movie ranks we get a strict turnstile stream --- 
in fact the delta $r$ for every stream element is positive.

The simplest algorithm to solve our problem is then simply calculating the
frequency vector for the stream, and sort it when our algorithm is queried.
However, this algorithm is not very satisfactory. The working memory is
sublinear in the cardinality of the stream, but not in the universe size. It
does not provide a current solution either, as we have to sort the frequency
vector when queried. On the positive side, the solution provided by the
algorithm is correct. To be precise, this algorithm would require $O(m)$ working
memory, and time for each stream item, $m$ being the number of distinct movies
in the stream, or the universe size $|U|$. A query would then require
$O(n \log(m))$ time, which is unacceptable.

\begin{enumerate}
	\item{Maintaining ordering with each item}
	\item{Approximation based on sampling}
	\item{sketching approach to approximation}
\end{enumerate}

For 1 --- maintaining ordering --- we diverge from the classical definition of
streaming algorithms. Both by using linear memory, and by using non-constant
time for each stream item. Although the latter is common, it is unusual to use
time non-constant in the stream size. We note that this solution will be
equivalent to maintaining an ordered set of running averages, and is thus the
same as the online-sorting approach. Knowing that for most stream items $(j,r)$,
the movie represented by $j$ will already be in the ordered set, it might be
possible to achieve insertion time linear in the number of inversions needed to
reorder the set, though it is not clear that this improves on the
$log(n)$ insertion time in binary search trees..

For 2 --- sampling the stream --- there seem to be two obvious approaches;
Sampling as normal (reservoir sampling) over the stream, or sampling over the
movies, deliberately making sure that all movies are represented in the sample,
or that the number of samples...
Neither seem to be much good

Finally 3 --- sketching --- looks good. We can use \texttt{Count-Min sketch} to
get approximate point-queries (although we would query all points, or at least
max-k points). It may even be possible to combine this solution
with 1, to avoid sorting the samples when queried, though this requires further
analysis.

