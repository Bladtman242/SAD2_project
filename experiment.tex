\section{Experiment}
While the modified Count-min sketch algorithm provides an error bound for the
estimated movie averages, what we are really interested in is how much it
affects the ordering of the movies when sorted by these estimated averages
compared to the real averages. In this section, we evaluate the modified
Count-min sketch algorithm by running it on real-life data, and comparing the
order it produces with the correct order. 

We quantify the error in ordering by the Kendall tau distance. For a permutation
of movies $\pi$, we say that $x <_\pi y$ if $x$ comes before $y$ in $\pi$. The
Kendall tau distance between two orderings of our movie set is then $\mathrm{KT}
\left(\pi_1,\pi_2\right) = \left|\{x,y\}: x <_{\pi_1} y \wedge y <_{\pi_2}
x\right|$. The Kendall distance is often normalized to the maximum number of
inversions between the orderings, $n(n-1)/2$ for $n$ elements. We expect random
orderings to have a normalized Kendall tau distance of $\frac{1}{2}$, so
only results with a lower distance can be considered useful.

\subsection{Results}
Our data is sampled from the \textit{Netflix
Prize}\footnotemark \ data set.
The full data set contains more than 100 million user ratings, for more than 17
thousand movies.
We test the algorithm on three samples of the \texttt{Netflix} data:

\footnotetext{http://academictorrents.com/details/9b13183dc4d60676b773c9e2cd6de5e5542cee9a}
\begin{itemize}
	\item \textit{100; ratings} contains all ratings for the $13726$ most
		frequently rated movies. Roughly 100 million ratings total,
	\item \textit{50Mmin ratings} contains all ratings for the $17146$ least
		frequently rated movies. Roughly 50 million ratings total,
	\item \textit{50M ratings} contains all ratings for the $611$ most
		frequently rated movies. Roughly 50 million ratings total,
	\item \textit{min10K ratings} contains all ratings for the $2042$ movies that have more
		than $10.000$ ratings.

\end{itemize}

\pgfplotsset{scaled x ticks=false}
\begin{center}
\begin{tikzpicture}
\begin{axis}[
	title=Count-min order error,
	xlabel={Error bound $\varepsilon$},
	ylabel={KT. norm.},
	legend pos=south east,
	xticklabel style={
		/pgf/number format/.cd,
		fixed,
		fixed zerofill,
		precision=3,
		/tikz/.cd
	},
]
\addplot table [y=100M,x=E]{allresults};
\addlegendentry{\textit{100M ratings}}
\addplot table [y=50M,x=E]{allresults};
\addlegendentry{\textit{50M ratings}}
\addplot table [y=min10K,x=E]{allresults};
\addlegendentry{\textit{min10K ratings}}
\addplot table [y=50Mmin,x=E]{allresults};
\addlegendentry{\textit{50Mmin ratings}}
\end{axis}
\end{tikzpicture}
\end{center}

All trials are run with $\delta = 0.01$.

As expected, the algorithm performs much worse on the large, $100M raitings$
dataset than on the smaller data sets.
For $\varepsilon = 0.001$, the normalized Kendall-Tau distance is $0.33$, and it
rapidly approaches $0.5$.

The obvious explanation is the error's dependency on the length of the stream,
but there is another factor at play.

Because of the way the Count-Min algorithm works --- adding up the ratings when the
hash functions have collisions --- there is a tendency that movies with fewer
ratings will cause inversions more often than movies with many ratings.
Futhermore, we see that that the algorithm performs reasonable well in the two
other data sets, containing only movies with many ratings.

We see however, that in order to save memory compared to the simple
approaches described in section \ref{sec:sorting}, we have to accept a
normalized Kendall tau distance of at least $0.1$, or choose a higher value for $\delta$

\subsection{Implementation}
The implementation can be found in the appendices.
We Note that the implementation does not live up to the performance
bounds stated in section \ref{sec:sketching}. This is not a problem, since we
are assessing the correctness of the algorithm, not it's throughput. The
implementation differs in two ways: To emulate querying all data points, a list
of all observed movies is kept, requiring $O(|U|)$ extra memory. Furthermore the
ratings are sorted when queried, rather than maintaining the ordering
dynamically. Again, this does not effect the experiment.
