\documentclass[a4paper, titlepage]{report}

\usepackage[utf8]{inputenc}
\usepackage{courier} % Required for the courier font
\usepackage[bookmarks]{hyperref}
\usepackage{amsfonts}

%redefine percentage sign to be a little smaller
\let\oldpct\%
\renewcommand{\%}{\scalebox{.9}{\oldpct}}
\begin{document}

\title{SAD2 exam report}
\author{
	Radoslaw Niemczyk
	\\\texttt{radn@itu.dk}
	\and
	Sigurt Bladt Dinesen
	\\\texttt{sidi@itu.dk}
}

\maketitle

%\tableofcontents

\section*{Ordering movie ratings in a dynamic setting}
Ranking has become an increasingly important problem, with ever-growing datasets
both in the industry and in academia.

Ranking is used commercially to provide customers with proposed subsets of
products, to make it easier to choose a product of interest. For this it might
be valuable to have the entire set of products ordered by rank, but it may be
sufficient to have a \textit{top-n} list, of the $m$ highest (and/or lowest)
ranked items.

In a static setting, where the data does not evolve over time, this has several
simple solutions: sorting the full data set, or probing for the $m$ largest
elements. In a dynamic setting however, were the data evolves over time, those
solutions would need to be re-run to maintain current solutions. Hence, there
may be better solutions that evolve the solutions as the data evolves, or is
based on approximation.

To motivate our approach, we present it through the following concrete problem:
A service maintains a list of movies, and lets users rank movies on some scale
(say $\left[1,10\right]\cap \mathbb{N}$). We want to provide an ordered set of the best $m$ out of
$m$ movies were $m\leq n$ (In particular, $m$ might be equal to $n$).
In this setting, we want to explore trade-offs between memory consumption,
correctness, and  currency. In particular it should be possible to achieve a
memory bound lower than $m$ by sacrificing correctness, achieve both by
sacrificing currency, i.e. allowing the output to become somewhat outdated as
the underlying data set evolves.

Following is a list of techniques that we deemed promising at the project
outset, and hence wished explore the effectiveness of with respect to our
problem:

\begin{description}
	\item[Parallelization] The use of parallelized sorting algorithms, such
		as parallelized merge- or radix- sort. Parallization in algorithms is very
		natural for sorting/selection. But it is still very overlooked. It might be
		a challening to see the real impact of this - because we are affecting the
		overall time consmuption by using it. Moreover usally we are adding more
		complexity and overhead to our solution - by creating and mantaining parallel
		task and jobs. This mean on of our point of emphasis will analysis of the
		pros and cons carried by this approach.
	\item[Approximation] We would like to explore the possibility of
		performing an approximate sort. User--provided rankings are
		often inconsistent. For instance, if a user ranks a move $m$
		lower than a movie $m'$, does that mean he liked $m$ less, or
		that he likes that genre less? It is unclear weather or not the
		scale is linear, and the same user may have different
		experiences on different days. This means that an \textit{exact}
		ordering might not be necessary. If it provides a speedup, it
		may be well worth it to perform a partial sorting of the
		rankings --- such that a top--ten might really be a top--eight,
		plus 12 and 14.
	\item[Online sorting] Sorting is an inherently offline problem --- you
		can not sort a set without having all the values. However, for
		problems where the full data set is not immediately available,
		onlineness can be achieved, or approximated, by sorting partial
		data sets, and then in the end sorting the whole. Exploiting the
		efficiency of certain sorting algorithms when dealing with
		partially ordered data, to lessen the time spend waiting for the
		data.

\end{description}

\input{./onlinesort.tex}

\input{./streamingsampling.tex}

\end{document}
